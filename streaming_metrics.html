<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>streamauc.streaming_metrics API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>streamauc.streaming_metrics</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="streamauc.streaming_metrics.StreamingMetrics"><code class="flex name class">
<span>class <span class="ident">StreamingMetrics</span></span>
<span>(</span><span>num_thresholds: int = 200, num_classes: int = 2, thresholds: Union[List[float], numpy.ndarray, None] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for keeping track of metrics for many thresholds in a
minibatch-wise, iterative, fashion.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>num_thresholds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of thresholds to evaluate the curve. Default is 200.</dd>
<dt><strong><code>num_classes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of classes in the multiclass setting. Must be &gt;= 2.</dd>
<dt><strong><code>thresholds</code></strong> :&ensp;<code>list</code> of <code>float</code>, optional</dt>
<dd>List of specific thresholds to evaluate the metrics at.
A probability &gt;= threshold is defined as a positive prediction for
the respective class.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StreamingMetrics:
    &#34;&#34;&#34;
    Class for keeping track of metrics for many thresholds in a
    minibatch-wise, iterative, fashion.

    Parameters
    ----------
    num_thresholds : int, optional
        Number of thresholds to evaluate the curve. Default is 200.
    num_classes : int
        Number of classes in the multiclass setting. Must be &gt;= 2.
    thresholds : list of float, optional
        List of specific thresholds to evaluate the metrics at.
        A probability &gt;= threshold is defined as a positive prediction for
        the respective class.
    &#34;&#34;&#34;

    def __init__(
        self,
        num_thresholds: int = 200,
        num_classes: int = 2,
        thresholds: Optional[Union[List[float], np.ndarray]] = None,
    ):
        if num_classes &lt; 2:
            raise ValueError(&#34;Argument `num_classes` must be an integer &gt;= 2.&#34;)

        self.num_classes = num_classes

        self.num_thresholds, self.thresholds = _validate_thresholds(
            num_thresholds, thresholds
        )

        self._confusion_matrix = np.zeros(
            (self.num_thresholds, self.num_classes, 2, 2),
            dtype=int,
        )

    @property
    def confusion_matrix(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        For each threshold, and for each class, there is a 2x2 confusion
        matrix. The entries of each confusion matrix correspond to the
        labels of:
        np.array([ [&#34;TP&#34;,&#34;FN&#34;],
                   [&#34;FP&#34;, &#34;TN&#34;]
                   ])

        That is, the indices are given by:
        TP: self.confusion_matrix[..., 0,0]
        FP: self.confusion_matrix[..., 1,0]
        FN: self.confusion_matrix[..., 0,1]
        TN: self.confusion_matrix[..., 1,1]

        Note, that this corresponds to the flipped confusion matrix of
        sklearn. We prefer this order, as it corresponds to many written
        references, e.g. the wikipedia page.

        That is, self.confusion_matrix = np.flip(sklearn_confusion_matrix)

        &#34;&#34;&#34;
        return self._confusion_matrix

    def reset(self):
        &#34;&#34;&#34;
        Reset the intermediate values for the confusion matrix.
        &#34;&#34;&#34;
        self._confusion_matrix = np.zeros(
            (self.num_thresholds, self.num_classes, 2, 2),
            dtype=int,
        )

    def update(
        self,
        y_true: np.ndarray,
        y_score: np.ndarray,
        check_inputs: bool = True,
    ):
        &#34;&#34;&#34;
        Update the intermediate values based on streaming data.

        Parameters
        ----------
        y_true : np.ndarray
            Ground truth labels of shape [-1] (or [-1, 1], [-1, 1, 1, 1]...)
            with values indicating the class index. Alternatively, may also
            be one-hot encoded labels of shape [-1, num_classes].
        y_score : np.ndarray
            Predicted probabilities for each class of shape[-1, num_classes]

        Raises
        ------
        ValueError
            If the shapes of `y_true` and `y_pred` do not match.
        &#34;&#34;&#34;

        y_true = np.squeeze(y_true).astype(int)
        y_score = np.squeeze(y_score)

        if check_inputs:
            if y_true.ndim &gt; 2:
                raise ValueError(
                    f&#34;Unknown shape of y_true: {y_true.shape},&#34;
                    f&#34;must be squeezable to either [-1, num_classes] or [-1].&#34;
                )
            if y_true.ndim == 2 and np.any(y_true.sum(-1) != 1):
                raise ValueError(&#34;The provided one-hot encoding is invalid.&#34;)
            if y_score.ndim &gt; 2:
                raise ValueError(
                    f&#34;Unknown shape of y_true: {y_true.shape},&#34;
                    f&#34;must be squeezable to either [-1, num_classes] or [-1].&#34;
                )

            if not (y_true.shape[0] == y_score.shape[0]):
                raise ValueError(
                    &#34;Number of samples in y_true and y_pred must match&#34;
                )

            if (y_score.ndim == 2) and (y_score.shape[1] != self.num_classes):
                raise ValueError(f&#34;Invalid shape of y_pred: {y_score.shape}&#34;)

        if y_true.ndim == 2 and y_true.shape[1] == self.num_classes:
            y_onehot = y_true
        else:
            y_onehot = np.eye(self.num_classes, dtype=int)[y_true]

        # use numpy broadcasting to get predictions
        pred_pos = y_score[np.newaxis, ...] &gt;= self.thresholds.reshape(
            -1, 1, 1
        )
        is_pos = y_onehot[np.newaxis, ...]

        # sum over the minibatch samples
        tp = np.sum(pred_pos &amp; is_pos, 1)
        fp = np.sum(pred_pos &amp; (~is_pos), 1)
        fn = np.sum((~pred_pos) &amp; (is_pos), 1)
        tn = np.sum((~pred_pos) &amp; (~is_pos), 1)

        # update confusion matrix entry
        self._confusion_matrix[..., 0, 0] += tp
        self._confusion_matrix[..., 1, 0] += fp
        self._confusion_matrix[..., 1, 1] += tn
        self._confusion_matrix[..., 0, 1] += fn

    def _total(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate total for each threshold and class.
        Of course, this should be the same value for all thresholds.

        Returns
        -------
        np.ndarray
            Total at each threshold.
        &#34;&#34;&#34;
        total = self.confusion_matrix.sum(-1).sum(-1)
        return total

    def true_positives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate true positives for each threshold and class.

        Returns
        -------
        np.ndarray
            True positives at each threshold.
        &#34;&#34;&#34;

        return self.confusion_matrix[..., 0, 0]
        # tp = np.diagonal(self._confusion_matrix, axis1=1, axis2=2)
        # return tp

    def false_positives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate false positives for each threshold and class.

        Returns
        -------
        np.ndarray
            False positives at each threshold.
        &#34;&#34;&#34;
        # tp = self.true_positives()
        # pp = self.predicted_positives()
        #
        # fp = pp - tp
        # return fp

        return self.confusion_matrix[..., 1, 0]

    def true_negatives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate the total negatives for each threshold and class.

        Returns
        -------
        np.ndarray
            Negatives at each threshold.
        &#34;&#34;&#34;

        return self.confusion_matrix[..., 1, 1]

    def false_negatives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate false negatives for each threshold and class.

        Returns
        -------
        np.ndarray
            False negatives at each threshold.
        &#34;&#34;&#34;
        # tp = self.true_positives()
        # p = self.positives()
        #
        # fn = p - tp
        return self.confusion_matrix[..., 0, 1]

    def positives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate the total positives for each threshold and class.

        Returns
        -------
        np.ndarray
            Positives at each threshold.
        &#34;&#34;&#34;
        # return np.sum(self._confusion_matrix, axis=-1)
        return (
            self.confusion_matrix[..., 0, 0] + self.confusion_matrix[..., 0, 1]
        )

    def negatives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate the total negatives for each threshold and class.

        Returns
        -------
        np.ndarray
            Negatives at each threshold.
        &#34;&#34;&#34;

        return self._total() - self.positives()

    def predicted_positives(self):
        &#34;&#34;&#34;
        Calculate predicted positives for each threshold and class.

        Returns
        -------
        np.ndarray
            Predicted positives at each threshold.
        &#34;&#34;&#34;

        return (
            self.confusion_matrix[..., 0, 0] + self.confusion_matrix[..., 1, 0]
        )

    def predicted_negatives(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Calculate predicted negatives for each threshold and class.

        Returns
        -------
        np.ndarray
            Predicted positives at each threshold.
        &#34;&#34;&#34;
        #
        # pp = self.predicted_positives()
        # total = self._total()
        #
        # pn = total - pp
        # return pn

        return (
            self.confusion_matrix[..., 0, 1] + self.confusion_matrix[..., 1, 1]
        )

    def calc_metric(
        self,
        metric: Callable,
        method: AggregationMethod = AggregationMethod.MACRO,
        class_index: Optional[int] = None,
        check_inputs=True,
    ):
        tp = self.true_positives()
        fp = self.false_positives()
        fn = self.false_negatives()
        tn = self.true_negatives()

        return metric(
            tp=tp,
            fp=fp,
            fn=fn,
            tn=tn,
            class_index=class_index,
            method=method,
            check_inputs=check_inputs,
        )

    def auc(
        self,
        metric_xaxis: Callable = metrics.fpr,
        metric_yaxis: Callable = metrics.tpr,
        method: AggregationMethod = AggregationMethod.ONE_VS_ALL,
        class_index: Optional[int] = None,
        check_inputs=True,
    ):

        metric_args = dict(
            tp=self.true_positives(),
            fp=self.false_positives(),
            fn=self.false_negatives(),
            tn=self.true_negatives(),
            class_index=class_index,
            method=method,
            check_inputs=check_inputs,
        )

        x_values = metric_xaxis(**metric_args)
        y_values = metric_yaxis(**metric_args)
        return auc(x_values, y_values)

    def precision_recall_curve(
        self,
        method: AggregationMethod = AggregationMethod.ONE_VS_ALL,
        class_index: Optional[int] = None,
        check_inputs: bool = True,
    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Compute precision and recall at all thresholds for plotting and auc
        computation. We adopt the behaviour of sklearn, in that the
        precision corresponding to a recall of 0 is 1.

        (Technically its undefined since its tp/(tp+fp) with tp=fp=0,
        but the value of 1 serves for stable plotting.)

        Parameters
        ----------
        method : AggregationMethod
            Method used to compute precision and recall for multiple classes.
            Micro and macro refer to the averaging method.
            Macro computes the metric for each class, and then averages the
            metrics.
            If &#39;1-vs-all&#39; the index for the positive class has to be defined
            in &#39;class_index&#39;. All other classes will be summarized as the
            negative class.

            Must be one of [&#34;macro&#34;,&#34;micro&#34;,&#34;1-vs-all&#34;].

        class_index : int, optional
            Class index for &#34;1-vs-all&#34; calculation.
             Required if `method` is &#34;1-vs-all&#34;.

        Returns
        -------
        precision : np.ndarray
            Precision values at each threshold.
        recall : np.ndarray
            Recall values at each threshold.
        &#34;&#34;&#34;
        tp = self.true_positives()
        fp = self.false_positives()
        fn = self.false_negatives()

        precision = metrics.precision(
            tp=tp,
            fp=fp,
            method=method,
            class_index=class_index,
            check_inputs=check_inputs,
        )

        recall = metrics.recall(
            tp=tp,
            fn=fn,
            method=method,
            class_index=class_index,
            check_inputs=check_inputs,
        )
        # ensure precision 1 at recall 0
        # precision[0] = 1.0
        return (
            precision[::-1][1:].squeeze(),
            recall[::-1][1:].squeeze(),
            self.thresholds[1:][::-1].squeeze(),
        )

    def roc_curve(
        self,
        method: AggregationMethod = AggregationMethod.ONE_VS_ALL,
        class_index: Optional[int] = None,
        check_inputs: bool = True,
    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:
        tp = self.true_positives()
        fp = self.false_positives()
        fn = self.false_negatives()
        tn = self.true_negatives()

        _tpr = metrics.tpr(
            tp=tp,
            fn=fn,
            method=method,
            class_index=class_index,
            check_inputs=check_inputs,
        )
        _fpr = metrics.fpr(
            fp=fp,
            tn=tn,
            method=method,
            class_index=class_index,
            check_inputs=check_inputs,
        )
        return _fpr.squeeze(), _tpr.squeeze(), self.thresholds.squeeze()

    def plot_roc_curve(
        self,
        class_names: Optional[List[str]] = None,
        method=AggregationMethod.ONE_VS_ALL,
        class_index: Optional[int] = None,
        **kwargs,
    ) -&gt; plt.Figure:  #
        # pragma: nocover
        fpr, tpr, thresholds = self.roc_curve(
            method=method,
            class_index=class_index,
        )

        if method != AggregationMethod.ONE_VS_ALL:
            class_names = None
        return plot_curve_and_auc(
            x_values=fpr,
            y_values=tpr,
            thresholds=thresholds,
            class_names=class_names,
            **kwargs,
        )

    def plot_precision_recall_curve(
        self,
        class_names: Optional[List[str]] = None,
        method=AggregationMethod.ONE_VS_ALL,
        class_index: Optional[int] = None,
        **kwargs,
    ) -&gt; plt.Figure:  #

        # pragma: nocover
        precision, recall, thresholds = self.precision_recall_curve(
            method=method,
            class_index=class_index,
        )

        if method != AggregationMethod.ONE_VS_ALL:
            class_names = None
            assert (
                class_index is None
            ), &#34;class_index is only usable for ONE_VS_ALL&#34;
        return plot_curve_and_auc(
            x_values=recall,
            y_values=precision,
            thresholds=thresholds,
            class_names=class_names,
            **kwargs,
        )</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="streamauc.streaming_metrics.StreamingMetrics.confusion_matrix"><code class="name">prop <span class="ident">confusion_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"><p>For each threshold, and for each class, there is a 2x2 confusion
matrix. The entries of each confusion matrix correspond to the
labels of:
np.array([ ["TP","FN"],
["FP", "TN"]
])</p>
<p>That is, the indices are given by:
TP: self.confusion_matrix[&hellip;, 0,0]
FP: self.confusion_matrix[&hellip;, 1,0]
FN: self.confusion_matrix[&hellip;, 0,1]
TN: self.confusion_matrix[&hellip;, 1,1]</p>
<p>Note, that this corresponds to the flipped confusion matrix of
sklearn. We prefer this order, as it corresponds to many written
references, e.g. the wikipedia page.</p>
<p>That is, self.confusion_matrix = np.flip(sklearn_confusion_matrix)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def confusion_matrix(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    For each threshold, and for each class, there is a 2x2 confusion
    matrix. The entries of each confusion matrix correspond to the
    labels of:
    np.array([ [&#34;TP&#34;,&#34;FN&#34;],
               [&#34;FP&#34;, &#34;TN&#34;]
               ])

    That is, the indices are given by:
    TP: self.confusion_matrix[..., 0,0]
    FP: self.confusion_matrix[..., 1,0]
    FN: self.confusion_matrix[..., 0,1]
    TN: self.confusion_matrix[..., 1,1]

    Note, that this corresponds to the flipped confusion matrix of
    sklearn. We prefer this order, as it corresponds to many written
    references, e.g. the wikipedia page.

    That is, self.confusion_matrix = np.flip(sklearn_confusion_matrix)

    &#34;&#34;&#34;
    return self._confusion_matrix</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="streamauc.streaming_metrics.StreamingMetrics.auc"><code class="name flex">
<span>def <span class="ident">auc</span></span>(<span>self, metric_xaxis: Callable = &lt;function fpr&gt;, metric_yaxis: Callable = &lt;function tpr&gt;, method: <a title="streamauc.utils.AggregationMethod" href="utils.html#streamauc.utils.AggregationMethod">AggregationMethod</a> = AggregationMethod.ONE_VS_ALL, class_index: Optional[int] = None, check_inputs=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.calc_metric"><code class="name flex">
<span>def <span class="ident">calc_metric</span></span>(<span>self, metric: Callable, method: <a title="streamauc.utils.AggregationMethod" href="utils.html#streamauc.utils.AggregationMethod">AggregationMethod</a> = AggregationMethod.MACRO, class_index: Optional[int] = None, check_inputs=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.false_negatives"><code class="name flex">
<span>def <span class="ident">false_negatives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate false negatives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>False negatives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.false_positives"><code class="name flex">
<span>def <span class="ident">false_positives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate false positives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>False positives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.negatives"><code class="name flex">
<span>def <span class="ident">negatives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the total negatives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Negatives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.plot_precision_recall_curve"><code class="name flex">
<span>def <span class="ident">plot_precision_recall_curve</span></span>(<span>self, class_names: Optional[List[str]] = None, method=AggregationMethod.ONE_VS_ALL, class_index: Optional[int] = None, **kwargs) ‑> matplotlib.figure.Figure</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.plot_roc_curve"><code class="name flex">
<span>def <span class="ident">plot_roc_curve</span></span>(<span>self, class_names: Optional[List[str]] = None, method=AggregationMethod.ONE_VS_ALL, class_index: Optional[int] = None, **kwargs) ‑> matplotlib.figure.Figure</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.positives"><code class="name flex">
<span>def <span class="ident">positives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the total positives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Positives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.precision_recall_curve"><code class="name flex">
<span>def <span class="ident">precision_recall_curve</span></span>(<span>self, method: <a title="streamauc.utils.AggregationMethod" href="utils.html#streamauc.utils.AggregationMethod">AggregationMethod</a> = AggregationMethod.ONE_VS_ALL, class_index: Optional[int] = None, check_inputs: bool = True) ‑> Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Compute precision and recall at all thresholds for plotting and auc
computation. We adopt the behaviour of sklearn, in that the
precision corresponding to a recall of 0 is 1.</p>
<p>(Technically its undefined since its tp/(tp+fp) with tp=fp=0,
but the value of 1 serves for stable plotting.)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>AggregationMethod</code></dt>
<dd>
<p>Method used to compute precision and recall for multiple classes.
Micro and macro refer to the averaging method.
Macro computes the metric for each class, and then averages the
metrics.
If '1-vs-all' the index for the positive class has to be defined
in 'class_index'. All other classes will be summarized as the
negative class.</p>
<p>Must be one of ["macro","micro","1-vs-all"].</p>
</dd>
<dt><strong><code>class_index</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Class index for "1-vs-all" calculation.
Required if <code>method</code> is "1-vs-all".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>precision</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Precision values at each threshold.</dd>
<dt><strong><code>recall</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Recall values at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.predicted_negatives"><code class="name flex">
<span>def <span class="ident">predicted_negatives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predicted negatives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Predicted positives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.predicted_positives"><code class="name flex">
<span>def <span class="ident">predicted_positives</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predicted positives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Predicted positives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the intermediate values for the confusion matrix.</p></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.roc_curve"><code class="name flex">
<span>def <span class="ident">roc_curve</span></span>(<span>self, method: <a title="streamauc.utils.AggregationMethod" href="utils.html#streamauc.utils.AggregationMethod">AggregationMethod</a> = AggregationMethod.ONE_VS_ALL, class_index: Optional[int] = None, check_inputs: bool = True) ‑> Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.true_negatives"><code class="name flex">
<span>def <span class="ident">true_negatives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the total negatives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Negatives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.true_positives"><code class="name flex">
<span>def <span class="ident">true_positives</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate true positives for each threshold and class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>True positives at each threshold.</dd>
</dl></div>
</dd>
<dt id="streamauc.streaming_metrics.StreamingMetrics.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, y_true: numpy.ndarray, y_score: numpy.ndarray, check_inputs: bool = True)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the intermediate values based on streaming data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Ground truth labels of shape [-1] (or [-1, 1], [-1, 1, 1, 1]&hellip;)
with values indicating the class index. Alternatively, may also
be one-hot encoded labels of shape [-1, num_classes].</dd>
<dt><strong><code>y_score</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Predicted probabilities for each class of shape[-1, num_classes]</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the shapes of <code>y_true</code> and <code>y_pred</code> do not match.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="streamauc" href="index.html">streamauc</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="streamauc.streaming_metrics.StreamingMetrics" href="#streamauc.streaming_metrics.StreamingMetrics">StreamingMetrics</a></code></h4>
<ul class="">
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.auc" href="#streamauc.streaming_metrics.StreamingMetrics.auc">auc</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.calc_metric" href="#streamauc.streaming_metrics.StreamingMetrics.calc_metric">calc_metric</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.confusion_matrix" href="#streamauc.streaming_metrics.StreamingMetrics.confusion_matrix">confusion_matrix</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.false_negatives" href="#streamauc.streaming_metrics.StreamingMetrics.false_negatives">false_negatives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.false_positives" href="#streamauc.streaming_metrics.StreamingMetrics.false_positives">false_positives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.negatives" href="#streamauc.streaming_metrics.StreamingMetrics.negatives">negatives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.plot_precision_recall_curve" href="#streamauc.streaming_metrics.StreamingMetrics.plot_precision_recall_curve">plot_precision_recall_curve</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.plot_roc_curve" href="#streamauc.streaming_metrics.StreamingMetrics.plot_roc_curve">plot_roc_curve</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.positives" href="#streamauc.streaming_metrics.StreamingMetrics.positives">positives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.precision_recall_curve" href="#streamauc.streaming_metrics.StreamingMetrics.precision_recall_curve">precision_recall_curve</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.predicted_negatives" href="#streamauc.streaming_metrics.StreamingMetrics.predicted_negatives">predicted_negatives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.predicted_positives" href="#streamauc.streaming_metrics.StreamingMetrics.predicted_positives">predicted_positives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.reset" href="#streamauc.streaming_metrics.StreamingMetrics.reset">reset</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.roc_curve" href="#streamauc.streaming_metrics.StreamingMetrics.roc_curve">roc_curve</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.true_negatives" href="#streamauc.streaming_metrics.StreamingMetrics.true_negatives">true_negatives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.true_positives" href="#streamauc.streaming_metrics.StreamingMetrics.true_positives">true_positives</a></code></li>
<li><code><a title="streamauc.streaming_metrics.StreamingMetrics.update" href="#streamauc.streaming_metrics.StreamingMetrics.update">update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
